# æ“ä½œç³»ç»Ÿé¢è¯•è¯¦è§£ï¼ˆåŸºäºé‡å­å±‚æé¡¹ç›®å®æˆ˜ï¼‰

> **ç›®æ ‡**ï¼šé€šè¿‡çœŸå®é¡¹ç›®ä»£ç ç¤ºä¾‹ï¼Œæ·±å…¥ç†è§£æ“ä½œç³»ç»Ÿæ ¸å¿ƒæ¦‚å¿µï¼ŒæŒæ¡é¢è¯•å¿…å¤‡æŠ€èƒ½
> **é¡¹ç›®èƒŒæ™¯**ï¼šé‡å­æ€å±‚æé‡æ„ç³»ç»Ÿï¼ˆ5000+è¡Œä»£ç ï¼Œ90%æµ‹è¯•è¦†ç›–ç‡ï¼‰

---

## ğŸ“‹ ç›®å½•

1. [CPUè°ƒåº¦ä¸çº¿ç¨‹ç®¡ç†](#1-cpuè°ƒåº¦ä¸çº¿ç¨‹ç®¡ç†)
2. [å†…å­˜ç®¡ç†ä¸ç¼“å­˜ç­–ç•¥](#2-å†…å­˜ç®¡ç†ä¸ç¼“å­˜ç­–ç•¥)
3. [è¿›ç¨‹é—´é€šä¿¡ä¸åŒæ­¥](#3-è¿›ç¨‹é—´é€šä¿¡ä¸åŒæ­¥)
4. [æ–‡ä»¶ç³»ç»Ÿä¸I/Oæ“ä½œ](#4-æ–‡ä»¶ç³»ç»Ÿä¸ioæ“ä½œ)
5. [ç³»ç»Ÿè°ƒç”¨ä¸å†…æ ¸äº¤äº’](#5-ç³»ç»Ÿè°ƒç”¨ä¸å†…æ ¸äº¤äº’)
6. [ç½‘ç»œç¼–ç¨‹ä¸å¼‚æ­¥I/O](#6-ç½‘ç»œç¼–ç¨‹ä¸å¼‚æ­¥io)
7. [æ€§èƒ½ä¼˜åŒ–ä¸è°ƒè¯•](#7-æ€§èƒ½ä¼˜åŒ–ä¸è°ƒè¯•)
8. [é¢è¯•å®æˆ˜æ¼”ç»ƒ](#8-é¢è¯•å®æˆ˜æ¼”ç»ƒ)

---

## 1. CPUè°ƒåº¦ä¸çº¿ç¨‹ç®¡ç†

### 1.1 çº¿ç¨‹æ± è®¾è®¡ä¸ä»»åŠ¡è°ƒåº¦

**é¡¹ç›®èƒŒæ™¯**ï¼šé‡å­å±‚ææ‰¹å¤„ç†éœ€è¦å¤„ç†å¤§é‡æ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬åŒ…å«çº¿æ€§é‡æ„å’ŒMLEé‡æ„ä¸¤ä¸ªè®¡ç®—å¯†é›†å‹ä»»åŠ¡ã€‚

**æ ¸å¿ƒä»£ç **ï¼š
```python
# python/qtomography/app/controller.py:1315
from concurrent.futures import ThreadPoolExecutor
from threading import Event

class ReconstructionController:
    def run_batch_async(self, config: ReconstructionConfig, 
                       progress_callback: Optional[Callable] = None,
                       cancel_event: Optional[Event] = None) -> BatchResult:
        """å¼‚æ­¥æ‰¹å¤„ç†é‡æ„ä»»åŠ¡"""
        
        # åˆ›å»ºçº¿ç¨‹æ± 
        with ThreadPoolExecutor(max_workers=4) as executor:
            futures = []
            
            for idx, sample in enumerate(samples):
                # æ£€æŸ¥å–æ¶ˆä¿¡å·
                if cancel_event and cancel_event.is_set():
                    break
                    
                # æäº¤ä»»åŠ¡åˆ°çº¿ç¨‹æ± 
                future = executor.submit(self._process_single_sample, 
                                       idx, sample, config)
                futures.append(future)
                
                # å®šæœŸæ£€æŸ¥è¿›åº¦
                if idx % 10 == 0 and progress_callback:
                    progress_callback(idx, len(samples))
            
            # æ”¶é›†ç»“æœ
            results = []
            for future in futures:
                try:
                    result = future.result(timeout=30)  # 30ç§’è¶…æ—¶
                    results.append(result)
                except TimeoutError:
                    logger.warning("Sample processing timeout")
                except Exception as e:
                    logger.error(f"Sample processing failed: {e}")
            
        return BatchResult(results)
```

**é¢è¯•è¦ç‚¹**ï¼š

1. **ä¸ºä»€ä¹ˆé€‰æ‹©ThreadPoolExecutorè€Œä¸æ˜¯æ‰‹åŠ¨åˆ›å»ºçº¿ç¨‹ï¼Ÿ**
   - çº¿ç¨‹å¤ç”¨ï¼šé¿å…é¢‘ç¹åˆ›å»º/é”€æ¯çº¿ç¨‹çš„å¼€é”€
   - èµ„æºæ§åˆ¶ï¼šé™åˆ¶æœ€å¤§çº¿ç¨‹æ•°ï¼Œé˜²æ­¢èµ„æºè€—å°½
   - å¼‚å¸¸å¤„ç†ï¼šç»Ÿä¸€çš„å¼‚å¸¸æ•è·å’Œè¶…æ—¶æ§åˆ¶
   - ç»“æœæ”¶é›†ï¼šFutureå¯¹è±¡æä¾›å¼‚æ­¥ç»“æœè·å–

2. **å¦‚ä½•å®ç°ä»»åŠ¡å–æ¶ˆï¼Ÿ**
   ```python
   # ä½¿ç”¨Eventå¯¹è±¡ä½œä¸ºå–æ¶ˆä¿¡å·
   cancel_event = Event()
   
   # åœ¨ä»»åŠ¡ä¸­æ£€æŸ¥å–æ¶ˆä¿¡å·
   def _process_single_sample(self, idx, sample, config):
       for iteration in range(max_iterations):
           if cancel_event.is_set():
               logger.info(f"Task {idx} cancelled")
               return None
           # æ‰§è¡Œè®¡ç®—...
   ```

3. **çº¿ç¨‹å®‰å…¨è€ƒè™‘**ï¼š
   - å…±äº«çŠ¶æ€ä½¿ç”¨é”ä¿æŠ¤
   - é¿å…åœ¨æŒé”çŠ¶æ€ä¸‹è¿›è¡ŒI/Oæ“ä½œ
   - ä½¿ç”¨ä¸å¯å˜å¯¹è±¡ä¼ é€’æ•°æ®

### 1.2 GUIå“åº”æ€§ä¿è¯

**é¡¹ç›®èƒŒæ™¯**ï¼šExcelå±‚æå·¥å…·éœ€è¦ä¿æŒç•Œé¢å“åº”ï¼Œé¿å…é•¿æ—¶é—´è®¡ç®—é˜»å¡UIã€‚

**æ ¸å¿ƒä»£ç **ï¼š
```python
# python/excel_tomography_gui.py:250
import threading
import tkinter as tk

class ExcelTomographyGUI:
    def start_processing(self):
        """å¯åŠ¨åå°å¤„ç†ï¼Œä¿æŒGUIå“åº”"""
        
        # ç¦ç”¨UIæ§ä»¶
        self.progress_bar.config(state='disabled')
        self.start_button.config(state='disabled')
        
        # åˆ›å»ºåå°çº¿ç¨‹
        self.processing_thread = threading.Thread(
            target=self._background_processing,
            daemon=True  # è®¾ç½®ä¸ºå®ˆæŠ¤çº¿ç¨‹
        )
        self.processing_thread.start()
    
    def _background_processing(self):
        """åå°å¤„ç†å‡½æ•°"""
        try:
            # æ‰§è¡Œè€—æ—¶çš„é‡æ„è®¡ç®—
            results = self.controller.run_batch(self.config)
            
            # å›åˆ°ä¸»çº¿ç¨‹æ›´æ–°UI
            self.root.after(0, self._update_ui_with_results, results)
            
        except Exception as e:
            # é”™è¯¯å¤„ç†ä¹Ÿè¦å›åˆ°ä¸»çº¿ç¨‹
            self.root.after(0, self._show_error, str(e))
    
    def _update_ui_with_results(self, results):
        """åœ¨ä¸»çº¿ç¨‹ä¸­æ›´æ–°UI"""
        # é‡æ–°å¯ç”¨UIæ§ä»¶
        self.progress_bar.config(state='normal')
        self.start_button.config(state='normal')
        
        # æ›´æ–°ç»“æœæ˜¾ç¤º
        self.results_text.delete(1.0, tk.END)
        self.results_text.insert(1.0, str(results))
```

**é¢è¯•è¦ç‚¹**ï¼š

1. **ä¸ºä»€ä¹ˆGUIæ›´æ–°å¿…é¡»åœ¨ä¸»çº¿ç¨‹ï¼Ÿ**
   - GUIæ¡†æ¶ï¼ˆå¦‚Tkinterã€Qtï¼‰ä¸æ˜¯çº¿ç¨‹å®‰å…¨çš„
   - è·¨çº¿ç¨‹æ›´æ–°UIå¯èƒ½å¯¼è‡´å´©æºƒæˆ–æ˜¾ç¤ºå¼‚å¸¸
   - ä½¿ç”¨`root.after(0, callback)`å°†æ“ä½œè°ƒåº¦åˆ°ä¸»çº¿ç¨‹

2. **å®ˆæŠ¤çº¿ç¨‹çš„ä½œç”¨**ï¼š
   - `daemon=True`ï¼šä¸»ç¨‹åºé€€å‡ºæ—¶è‡ªåŠ¨ç»“æŸ
   - é¿å…åƒµå°¸çº¿ç¨‹é˜»å¡ç¨‹åºé€€å‡º
   - é€‚åˆåå°ä»»åŠ¡åœºæ™¯

### 1.3 å¤šè¿›ç¨‹vså¤šçº¿ç¨‹é€‰æ‹©

**é¡¹ç›®èƒŒæ™¯**ï¼šMLEé‡æ„æ˜¯CPUå¯†é›†å‹ä»»åŠ¡ï¼Œéœ€è¦è€ƒè™‘GILé™åˆ¶ã€‚

**æ ¸å¿ƒä»£ç **ï¼š
```python
# python/docs/teach/å¤šè¿›ç¨‹æ‰¹å¤„ç†æŠ€æœ¯è¯¦è§£.md
from multiprocessing import ProcessPoolExecutor, shared_memory
import numpy as np

class MultiprocessController:
    def __init__(self, max_workers=None):
        self.max_workers = max_workers or os.cpu_count()
    
    def process_samples_parallel(self, samples, config):
        """ä½¿ç”¨å¤šè¿›ç¨‹å¤„ç†æ ·æœ¬"""
        
        # åˆ›å»ºå…±äº«å†…å­˜å­˜å‚¨æŠ•å½±ç®—å­
        projector_matrix = self._create_projector_matrix(config.dimension)
        shm = shared_memory.SharedMemory(create=True, 
                                       size=projector_matrix.nbytes)
        shared_array = np.ndarray(projector_matrix.shape, 
                                 dtype=projector_matrix.dtype, 
                                 buffer=shm.buf)
        shared_array[:] = projector_matrix[:]
        
        try:
            with ProcessPoolExecutor(max_workers=self.max_workers) as executor:
                # æäº¤ä»»åŠ¡
                futures = []
                for idx, sample in enumerate(samples):
                    future = executor.submit(
                        self._process_worker,
                        idx, sample, config, shm.name
                    )
                    futures.append(future)
                
                # æ”¶é›†ç»“æœ
                results = [future.result() for future in futures]
                return results
                
        finally:
            # æ¸…ç†å…±äº«å†…å­˜
            shm.close()
            shm.unlink()
    
    def _process_worker(self, idx, sample, config, shm_name):
        """å·¥ä½œè¿›ç¨‹å‡½æ•°"""
        # é‡æ–°è¿æ¥å…±äº«å†…å­˜
        shm = shared_memory.SharedMemory(name=shm_name)
        projector_matrix = np.ndarray((config.dimension**2, config.dimension**2),
                                     dtype=np.complex128, buffer=shm.buf)
        
        # æ‰§è¡Œé‡æ„
        reconstructor = MLEReconstructor(config.dimension)
        result = reconstructor.reconstruct(sample, projector_matrix)
        
        shm.close()
        return result
```

**é¢è¯•è¦ç‚¹**ï¼š

1. **GILçš„å½±å“**ï¼š
   - Pythonçš„å…¨å±€è§£é‡Šå™¨é”é™åˆ¶å¤šçº¿ç¨‹åœ¨CPUå¯†é›†å‹ä»»åŠ¡ä¸­çš„æ€§èƒ½
   - å¤šè¿›ç¨‹å¯ä»¥ç»•è¿‡GILï¼Œå……åˆ†åˆ©ç”¨å¤šæ ¸CPU
   - I/Oå¯†é›†å‹ä»»åŠ¡å¤šçº¿ç¨‹ä»ç„¶æœ‰æ•ˆ

2. **è¿›ç¨‹é—´é€šä¿¡**ï¼š
   - å…±äº«å†…å­˜ï¼šé€‚åˆå¤§å‹æ•°ç»„æ•°æ®
   - é˜Ÿåˆ—ï¼šé€‚åˆæ¶ˆæ¯ä¼ é€’
   - æ–‡ä»¶ï¼šé€‚åˆç»“æœæŒä¹…åŒ–

---

## 2. å†…å­˜ç®¡ç†ä¸ç¼“å­˜ç­–ç•¥

### 2.1 LRUç¼“å­˜å®ç°

**é¡¹ç›®èƒŒæ™¯**ï¼šæŠ•å½±ç®—å­çŸ©é˜µè®¡ç®—æ˜‚è´µï¼Œéœ€è¦ç¼“å­˜ä¼˜åŒ–æ€§èƒ½ã€‚

**æ ¸å¿ƒä»£ç **ï¼š
```python
# python/qtomography/infrastructure/cache/optimized_lru.py
import threading
from collections import OrderedDict
from typing import Any, Optional

class OptimizedLRUCache:
    """çº¿ç¨‹å®‰å…¨çš„LRUç¼“å­˜å®ç°"""
    
    def __init__(self, max_size: int = 100):
        self.max_size = max_size
        self._cache = OrderedDict()
        self._lock = threading.RLock()  # å¯é‡å…¥é”
        self._hits = 0
        self._misses = 0
    
    def get(self, key: Any) -> Optional[Any]:
        """è·å–ç¼“å­˜é¡¹"""
        with self._lock:
            if key in self._cache:
                # ç§»åŠ¨åˆ°æœ«å°¾ï¼ˆæœ€è¿‘ä½¿ç”¨ï¼‰
                value = self._cache.pop(key)
                self._cache[key] = value
                self._hits += 1
                return value
            else:
                self._misses += 1
                return None
    
    def put(self, key: Any, value: Any) -> None:
        """æ·»åŠ ç¼“å­˜é¡¹"""
        with self._lock:
            if key in self._cache:
                # æ›´æ–°ç°æœ‰é¡¹
                self._cache.pop(key)
            elif len(self._cache) >= self.max_size:
                # åˆ é™¤æœ€ä¹…æœªä½¿ç”¨çš„é¡¹
                self._cache.popitem(last=False)
            
            self._cache[key] = value
    
    def clear(self) -> None:
        """æ¸…ç©ºç¼“å­˜"""
        with self._lock:
            self._cache.clear()
            self._hits = 0
            self._misses = 0
    
    @property
    def hit_rate(self) -> float:
        """ç¼“å­˜å‘½ä¸­ç‡"""
        total = self._hits + self._misses
        return self._hits / total if total > 0 else 0.0
```

**é¢è¯•è¦ç‚¹**ï¼š

1. **ä¸ºä»€ä¹ˆä½¿ç”¨RLockè€Œä¸æ˜¯Lockï¼Ÿ**
   - å¯é‡å…¥é”å…è®¸åŒä¸€çº¿ç¨‹å¤šæ¬¡è·å–é”
   - é¿å…é€’å½’è°ƒç”¨æˆ–è£…é¥°å™¨å¯¼è‡´çš„æ­»é”
   - æé«˜ä»£ç çš„çµæ´»æ€§å’Œå®‰å…¨æ€§

2. **ç¼“å­˜ç­–ç•¥é€‰æ‹©**ï¼š
   - LRUï¼šé€‚åˆæ—¶é—´å±€éƒ¨æ€§å¼ºçš„è®¿é—®æ¨¡å¼
   - LFUï¼šé€‚åˆé¢‘ç‡åˆ†å¸ƒä¸å‡åŒ€çš„åœºæ™¯
   - TTLï¼šé€‚åˆæœ‰æ—¶é—´é™åˆ¶çš„æ•°æ®

### 2.2 å†…å­˜ä¼˜åŒ–æŠ€å·§

**é¡¹ç›®èƒŒæ™¯**ï¼šå¤§å‹å¯†åº¦çŸ©é˜µï¼ˆ16x16å¤æ•°çŸ©é˜µï¼‰éœ€è¦ä¼˜åŒ–å†…å­˜ä½¿ç”¨ã€‚

**æ ¸å¿ƒä»£ç **ï¼š
```python
# python/qtomography/domain/density.py
import numpy as np
import gc

class DensityMatrix:
    """å¯†åº¦çŸ©é˜µç±»ï¼Œä¼˜åŒ–å†…å­˜ä½¿ç”¨"""
    
    def __init__(self, matrix: np.ndarray):
        # ä½¿ç”¨è§†å›¾è€Œä¸æ˜¯å‰¯æœ¬
        self._matrix = matrix.view()
        self._ensure_physical()
    
    def normalize(self) -> 'DensityMatrix':
        """åŸåœ°å½’ä¸€åŒ–ï¼Œé¿å…åˆ›å»ºæ–°å¯¹è±¡"""
        trace = np.trace(self._matrix)
        if abs(trace) > 1e-12:
            self._matrix /= trace
        return self
    
    def ensure_physical(self, tolerance: float = 1e-12) -> 'DensityMatrix':
        """ç¡®ä¿ç‰©ç†æ€§ï¼ŒåŸåœ°ä¿®æ”¹"""
        # Hermitianå¯¹ç§°åŒ–
        self._matrix = (self._matrix + self._matrix.conj().T) / 2
        
        # ç‰¹å¾å€¼åˆ†è§£
        eigenvals, eigenvecs = np.linalg.eigh(self._matrix)
        
        # è£å‰ªè´Ÿç‰¹å¾å€¼
        eigenvals = np.maximum(eigenvals, tolerance)
        
        # é‡æ„çŸ©é˜µ
        self._matrix = eigenvecs @ np.diag(eigenvals) @ eigenvecs.conj().T
        
        return self.normalize()
    
    def __del__(self):
        """ææ„å‡½æ•°ï¼Œç¡®ä¿å†…å­˜é‡Šæ”¾"""
        if hasattr(self, '_matrix'):
            del self._matrix
        gc.collect()  # å¼ºåˆ¶åƒåœ¾å›æ”¶
```

**é¢è¯•è¦ç‚¹**ï¼š

1. **NumPyå†…å­˜ä¼˜åŒ–**ï¼š
   - ä½¿ç”¨è§†å›¾ï¼ˆviewï¼‰è€Œä¸æ˜¯å‰¯æœ¬ï¼ˆcopyï¼‰
   - åŸåœ°æ“ä½œï¼ˆin-place operationsï¼‰
   - åŠæ—¶é‡Šæ”¾ä¸éœ€è¦çš„æ•°ç»„

2. **å†…å­˜æ³„æ¼æ£€æµ‹**ï¼š
   ```python
   import tracemalloc
   
   # å¼€å§‹è·Ÿè¸ª
   tracemalloc.start()
   
   # æ‰§è¡Œæ“ä½œ
   result = process_large_data()
   
   # è·å–å†…å­˜ä½¿ç”¨æƒ…å†µ
   current, peak = tracemalloc.get_traced_memory()
   print(f"Current: {current / 1024 / 1024:.1f} MB")
   print(f"Peak: {peak / 1024 / 1024:.1f} MB")
   ```

---

## 3. è¿›ç¨‹é—´é€šä¿¡ä¸åŒæ­¥

### 3.1 ç”Ÿäº§è€…-æ¶ˆè´¹è€…æ¨¡å¼

**é¡¹ç›®èƒŒæ™¯**ï¼šæ‰¹å¤„ç†ä»»åŠ¡éœ€è¦è¿›åº¦æŠ¥å‘Šå’Œç»“æœæ”¶é›†ã€‚

**æ ¸å¿ƒä»£ç **ï¼š
```python
# python/qtomography/app/controller.py
import queue
import threading
from dataclasses import dataclass
from typing import Optional

@dataclass
class ProgressUpdate:
    """è¿›åº¦æ›´æ–°æ¶ˆæ¯"""
    sample_id: int
    progress: float
    status: str
    result: Optional[Any] = None

class ProgressReporter:
    """è¿›åº¦æŠ¥å‘Šå™¨"""
    
    def __init__(self, callback: Optional[callable] = None):
        self.callback = callback
        self._queue = queue.Queue(maxsize=100)
        self._worker_thread = None
        self._stop_event = threading.Event()
    
    def start(self):
        """å¯åŠ¨è¿›åº¦æŠ¥å‘Šçº¿ç¨‹"""
        self._worker_thread = threading.Thread(
            target=self._report_worker,
            daemon=True
        )
        self._worker_thread.start()
    
    def report(self, sample_id: int, progress: float, 
               status: str, result: Optional[Any] = None):
        """æŠ¥å‘Šè¿›åº¦"""
        update = ProgressUpdate(sample_id, progress, status, result)
        try:
            self._queue.put_nowait(update)
        except queue.Full:
            # é˜Ÿåˆ—æ»¡æ—¶ä¸¢å¼ƒæ—§æ¶ˆæ¯
            try:
                self._queue.get_nowait()
                self._queue.put_nowait(update)
            except queue.Empty:
                pass
    
    def _report_worker(self):
        """è¿›åº¦æŠ¥å‘Šå·¥ä½œçº¿ç¨‹"""
        while not self._stop_event.is_set():
            try:
                update = self._queue.get(timeout=1.0)
                if self.callback:
                    self.callback(update)
                self._queue.task_done()
            except queue.Empty:
                continue
    
    def stop(self):
        """åœæ­¢æŠ¥å‘Š"""
        self._stop_event.set()
        if self._worker_thread:
            self._worker_thread.join(timeout=5.0)
```

**é¢è¯•è¦ç‚¹**ï¼š

1. **é˜Ÿåˆ—çš„ä½œç”¨**ï¼š
   - è§£è€¦ç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…
   - æä¾›ç¼“å†²æœºåˆ¶
   - æ”¯æŒå¼‚æ­¥é€šä¿¡

2. **çº¿ç¨‹å®‰å…¨è€ƒè™‘**ï¼š
   - `queue.Queue`æ˜¯çº¿ç¨‹å®‰å…¨çš„
   - ä½¿ç”¨`put_nowait()`å’Œ`get_nowait()`é¿å…é˜»å¡
   - è®¾ç½®é˜Ÿåˆ—å¤§å°é™åˆ¶é˜²æ­¢å†…å­˜æº¢å‡º

### 3.2 æ¡ä»¶å˜é‡ä¸åŒæ­¥

**é¡¹ç›®èƒŒæ™¯**ï¼šéœ€è¦ç­‰å¾…æ‰€æœ‰æ ·æœ¬å¤„ç†å®Œæˆæ‰èƒ½ç”Ÿæˆæ±‡æ€»æŠ¥å‘Šã€‚

**æ ¸å¿ƒä»£ç **ï¼š
```python
# python/qtomography/app/controller.py
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed

class BatchProcessor:
    """æ‰¹å¤„ç†å™¨ï¼Œä½¿ç”¨æ¡ä»¶å˜é‡åŒæ­¥"""
    
    def __init__(self, max_workers: int = 4):
        self.max_workers = max_workers
        self._lock = threading.Lock()
        self._condition = threading.Condition(self._lock)
        self._completed_count = 0
        self._total_count = 0
        self._results = []
    
    def process_batch(self, samples: list, config: dict) -> list:
        """å¤„ç†æ‰¹é‡æ ·æœ¬"""
        self._total_count = len(samples)
        self._completed_count = 0
        self._results = []
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            futures = {
                executor.submit(self._process_sample, idx, sample, config): idx
                for idx, sample in enumerate(samples)
            }
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(futures):
                try:
                    result = future.result()
                    with self._condition:
                        self._results.append(result)
                        self._completed_count += 1
                        
                        # é€šçŸ¥ç­‰å¾…çš„çº¿ç¨‹
                        self._condition.notify_all()
                        
                except Exception as e:
                    logger.error(f"Sample processing failed: {e}")
        
        return self._results
    
    def wait_for_completion(self, timeout: Optional[float] = None) -> bool:
        """ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ"""
        with self._condition:
            while self._completed_count < self._total_count:
                if not self._condition.wait(timeout):
                    return False
            return True
```

**é¢è¯•è¦ç‚¹**ï¼š

1. **æ¡ä»¶å˜é‡çš„ä½¿ç”¨åœºæ™¯**ï¼š
   - ç­‰å¾…ç‰¹å®šæ¡ä»¶æ»¡è¶³
   - é¿å…å¿™ç­‰å¾…ï¼ˆbusy waitingï¼‰
   - æä¾›æ›´é«˜æ•ˆçš„åŒæ­¥æœºåˆ¶

2. **æ­»é”é¢„é˜²**ï¼š
   - å›ºå®šé”çš„è·å–é¡ºåº
   - ä½¿ç”¨è¶…æ—¶æœºåˆ¶
   - é¿å…åµŒå¥—é”

---

## 4. æ–‡ä»¶ç³»ç»Ÿä¸I/Oæ“ä½œ

### 4.1 åŸå­æ–‡ä»¶æ“ä½œ

**é¡¹ç›®èƒŒæ™¯**ï¼šé‡æ„ç»“æœéœ€è¦å¯é ä¿å­˜ï¼Œé¿å…éƒ¨åˆ†å†™å…¥å¯¼è‡´çš„æ•°æ®æŸåã€‚

**æ ¸å¿ƒä»£ç **ï¼š
```python
# python/qtomography/infrastructure/persistence/result_repository.py
import tempfile
import os
import json
from pathlib import Path

class ResultRepository:
    """ç»“æœä»“åº“ï¼Œå®ç°åŸå­æ–‡ä»¶æ“ä½œ"""
    
    def save_atomic(self, record: ReconstructionRecord) -> Path:
        """åŸå­ä¿å­˜è®°å½•"""
        payload = record.to_serializable()
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        temp_fd, temp_path = tempfile.mkstemp(
            suffix='.json.tmp',
            dir=self.root
        )
        
        try:
            # å†™å…¥ä¸´æ—¶æ–‡ä»¶
            with os.fdopen(temp_fd, 'w', encoding='utf-8') as f:
                json.dump(payload, f, ensure_ascii=False, indent=2)
            
            # å¼ºåˆ¶åŒæ­¥åˆ°ç£ç›˜
            os.fsync(temp_fd)
            
            # ç”Ÿæˆæœ€ç»ˆæ–‡ä»¶å
            final_path = self.root / f"record_{record.dimension}_{record.timestamp}.json"
            
            # åŸå­é‡å‘½å
            os.rename(temp_path, final_path)
            
            return final_path
            
        except Exception:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.unlink(temp_path)
            except OSError:
                pass
            raise
    
    def load_with_checksum(self, path: Path) -> ReconstructionRecord:
        """å¸¦æ ¡éªŒå’Œçš„åŠ è½½"""
        import hashlib
        
        # è®¡ç®—æ–‡ä»¶æ ¡éªŒå’Œ
        with open(path, 'rb') as f:
            content = f.read()
            checksum = hashlib.md5(content).hexdigest()
        
        # éªŒè¯æ ¡éªŒå’Œ
        expected_checksum = self._get_expected_checksum(path)
        if checksum != expected_checksum:
            raise ValueError(f"Checksum mismatch for {path}")
        
        # åŠ è½½æ•°æ®
        payload = json.loads(content.decode('utf-8'))
        return ReconstructionRecord.from_serializable(payload)
```

**é¢è¯•è¦ç‚¹**ï¼š

1. **åŸå­æ“ä½œçš„å®ç°**ï¼š
   - å…ˆå†™ä¸´æ—¶æ–‡ä»¶
   - ä½¿ç”¨`fsync()`ç¡®ä¿æ•°æ®è½ç›˜
   - åŸå­é‡å‘½åï¼ˆ`rename()`æ˜¯åŸå­çš„ï¼‰

2. **æ•°æ®å®Œæ•´æ€§ä¿è¯**ï¼š
   - ä½¿ç”¨æ ¡éªŒå’ŒéªŒè¯æ–‡ä»¶å®Œæ•´æ€§
   - å¼‚å¸¸æ—¶æ¸…ç†ä¸´æ—¶æ–‡ä»¶
   - æä¾›æ¢å¤æœºåˆ¶

### 4.2 æ–‡ä»¶é”ä¸å¹¶å‘æ§åˆ¶

**é¡¹ç›®èƒŒæ™¯**ï¼šå¤šä¸ªè¿›ç¨‹å¯èƒ½åŒæ—¶è®¿é—®åŒä¸€ä¸ªç»“æœæ–‡ä»¶ã€‚

**æ ¸å¿ƒä»£ç **ï¼š
```python
# python/qtomography/infrastructure/persistence/file_lock.py
import fcntl
import time
from contextlib import contextmanager
from pathlib import Path

class FileLock:
    """æ–‡ä»¶é”å®ç°"""
    
    def __init__(self, lock_file: Path):
        self.lock_file = lock_file
        self.lock_file.parent.mkdir(parents=True, exist_ok=True)
    
    @contextmanager
    def acquire(self, timeout: float = 30.0):
        """è·å–æ–‡ä»¶é”"""
        lock_fd = None
        try:
            # æ‰“å¼€é”æ–‡ä»¶
            lock_fd = os.open(self.lock_file, os.O_CREAT | os.O_WRONLY)
            
            # å°è¯•è·å–æ’ä»–é”
            start_time = time.time()
            while time.time() - start_time < timeout:
                try:
                    fcntl.flock(lock_fd, fcntl.LOCK_EX | fcntl.LOCK_NB)
                    break
                except IOError:
                    time.sleep(0.1)
            else:
                raise TimeoutError(f"Failed to acquire lock within {timeout}s")
            
            yield lock_fd
            
        finally:
            if lock_fd is not None:
                try:
                    fcntl.flock(lock_fd, fcntl.LOCK_UN)
                except IOError:
                    pass
                os.close(lock_fd)

# ä½¿ç”¨ç¤ºä¾‹
def safe_write_result(result_path: Path, data: dict):
    """å®‰å…¨å†™å…¥ç»“æœ"""
    lock_file = result_path.with_suffix('.lock')
    
    with FileLock(lock_file).acquire():
        with open(result_path, 'w') as f:
            json.dump(data, f, indent=2)
        os.fsync(f.fileno())
```

**é¢è¯•è¦ç‚¹**ï¼š

1. **æ–‡ä»¶é”çš„ç±»å‹**ï¼š
   - æ’ä»–é”ï¼ˆLOCK_EXï¼‰ï¼šåªå…è®¸ä¸€ä¸ªè¿›ç¨‹å†™å…¥
   - å…±äº«é”ï¼ˆLOCK_SHï¼‰ï¼šå…è®¸å¤šä¸ªè¿›ç¨‹è¯»å–
   - éé˜»å¡é”ï¼ˆLOCK_NBï¼‰ï¼šç«‹å³è¿”å›ï¼Œä¸ç­‰å¾…

2. **æ­»é”é¢„é˜²**ï¼š
   - è®¾ç½®è¶…æ—¶æ—¶é—´
   - ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç¡®ä¿é”é‡Šæ”¾
   - é¿å…åµŒå¥—é”

---

## 5. ç³»ç»Ÿè°ƒç”¨ä¸å†…æ ¸äº¤äº’

### 5.1 è¿›ç¨‹åˆ›å»ºä¸ç®¡ç†

**é¡¹ç›®èƒŒæ™¯**ï¼šéœ€è¦å¯åŠ¨å¤–éƒ¨MATLABè¿›ç¨‹è¿›è¡Œå¯¹æ¯”éªŒè¯ã€‚

**æ ¸å¿ƒä»£ç **ï¼š
```python
# python/qtomography/infrastructure/external/matlab_runner.py
import subprocess
import tempfile
import signal
import os
from pathlib import Path

class MATLABRunner:
    """MATLABè¿›ç¨‹ç®¡ç†å™¨"""
    
    def __init__(self, matlab_path: str = "matlab"):
        self.matlab_path = matlab_path
        self.processes = {}  # è·Ÿè¸ªå­è¿›ç¨‹
    
    def run_matlab_script(self, script_path: Path, 
                         timeout: float = 300.0) -> subprocess.CompletedProcess:
        """è¿è¡ŒMATLABè„šæœ¬"""
        
        # å‡†å¤‡ç¯å¢ƒå˜é‡
        env = os.environ.copy()
        env['MATLABPATH'] = str(script_path.parent)
        
        # æ„å»ºå‘½ä»¤
        cmd = [
            self.matlab_path,
            '-batch',  # æ‰¹å¤„ç†æ¨¡å¼
            f"run('{script_path.name}')",
            '-wait'    # ç­‰å¾…å®Œæˆ
        ]
        
        try:
            # å¯åŠ¨å­è¿›ç¨‹
            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                env=env,
                cwd=str(script_path.parent)
            )
            
            # è®°å½•è¿›ç¨‹
            self.processes[process.pid] = process
            
            # ç­‰å¾…å®Œæˆæˆ–è¶…æ—¶
            try:
                stdout, stderr = process.communicate(timeout=timeout)
                return subprocess.CompletedProcess(
                    cmd, process.returncode, stdout, stderr
                )
            except subprocess.TimeoutExpired:
                # è¶…æ—¶å¤„ç†
                process.kill()
                stdout, stderr = process.communicate()
                raise TimeoutError(f"MATLAB script timeout after {timeout}s")
                
        finally:
            # æ¸…ç†è¿›ç¨‹è®°å½•
            if process.pid in self.processes:
                del self.processes[process.pid]
    
    def cleanup_all_processes(self):
        """æ¸…ç†æ‰€æœ‰å­è¿›ç¨‹"""
        for pid, process in list(self.processes.items()):
            try:
                if process.poll() is None:  # è¿›ç¨‹ä»åœ¨è¿è¡Œ
                    process.terminate()
                    process.wait(timeout=5.0)
            except subprocess.TimeoutExpired:
                process.kill()
            except ProcessLookupError:
                pass  # è¿›ç¨‹å·²ç»“æŸ
            finally:
                del self.processes[pid]
    
    def __del__(self):
        """ææ„å‡½æ•°ï¼Œç¡®ä¿æ¸…ç†"""
        self.cleanup_all_processes()
```

**é¢è¯•è¦ç‚¹**ï¼š

1. **è¿›ç¨‹åˆ›å»ºçš„ç³»ç»Ÿè°ƒç”¨**ï¼š
   - `fork()`ï¼šåˆ›å»ºå­è¿›ç¨‹
   - `exec()`ï¼šæ›¿æ¢è¿›ç¨‹æ˜ åƒ
   - `wait()`ï¼šç­‰å¾…å­è¿›ç¨‹ç»“æŸ

2. **è¿›ç¨‹ç®¡ç†æœ€ä½³å®è·µ**ï¼š
   - è®¾ç½®è¶…æ—¶é˜²æ­¢åƒµå°¸è¿›ç¨‹
   - ä½¿ç”¨ä¿¡å·å¤„ç†å­è¿›ç¨‹ç»ˆæ­¢
   - æ¸…ç†è¿›ç¨‹èµ„æº

### 5.2 ä¿¡å·å¤„ç†

**é¡¹ç›®èƒŒæ™¯**ï¼šéœ€è¦ä¼˜é›…å¤„ç†ç¨‹åºä¸­æ–­ä¿¡å·ã€‚

**æ ¸å¿ƒä»£ç **ï¼š
```python
# python/qtomography/app/signal_handler.py
import signal
import sys
import logging
from typing import List, Callable

class SignalHandler:
    """ä¿¡å·å¤„ç†å™¨"""
    
    def __init__(self):
        self.cleanup_handlers: List[Callable] = []
        self.shutdown_requested = False
    
    def register_cleanup(self, handler: Callable):
        """æ³¨å†Œæ¸…ç†å‡½æ•°"""
        self.cleanup_handlers.append(handler)
    
    def setup_signal_handlers(self):
        """è®¾ç½®ä¿¡å·å¤„ç†å™¨"""
        signal.signal(signal.SIGINT, self._handle_signal)
        signal.signal(signal.SIGTERM, self._handle_signal)
        
        # å¿½ç•¥SIGPIPEï¼ˆç®¡é“ç ´è£‚ï¼‰
        signal.signal(signal.SIGPIPE, signal.SIG_IGN)
    
    def _handle_signal(self, signum: int, frame):
        """ä¿¡å·å¤„ç†å‡½æ•°"""
        signal_name = signal.Signals(signum).name
        logging.info(f"Received signal {signal_name}, initiating graceful shutdown")
        
        self.shutdown_requested = True
        
        # æ‰§è¡Œæ¸…ç†å‡½æ•°
        for handler in self.cleanup_handlers:
            try:
                handler()
            except Exception as e:
                logging.error(f"Cleanup handler failed: {e}")
        
        # é€€å‡ºç¨‹åº
        sys.exit(0)

# ä½¿ç”¨ç¤ºä¾‹
def main():
    signal_handler = SignalHandler()
    signal_handler.setup_signal_handlers()
    
    # æ³¨å†Œæ¸…ç†å‡½æ•°
    signal_handler.register_cleanup(cleanup_temp_files)
    signal_handler.register_cleanup(cleanup_processes)
    
    # ä¸»å¾ªç¯
    while not signal_handler.shutdown_requested:
        process_batch()
```

**é¢è¯•è¦ç‚¹**ï¼š

1. **å¸¸è§ä¿¡å·ç±»å‹**ï¼š
   - `SIGINT`ï¼šä¸­æ–­ä¿¡å·ï¼ˆCtrl+Cï¼‰
   - `SIGTERM`ï¼šç»ˆæ­¢ä¿¡å·
   - `SIGKILL`ï¼šå¼ºåˆ¶ç»ˆæ­¢ï¼ˆæ— æ³•æ•è·ï¼‰
   - `SIGPIPE`ï¼šç®¡é“ç ´è£‚

2. **ä¿¡å·å¤„ç†æ³¨æ„äº‹é¡¹**ï¼š
   - ä¿¡å·å¤„ç†å‡½æ•°è¦ç®€å•å¿«é€Ÿ
   - é¿å…åœ¨ä¿¡å·å¤„ç†å‡½æ•°ä¸­è¿›è¡Œå¤æ‚æ“ä½œ
   - ä½¿ç”¨æ ‡å¿—ä½è€Œä¸æ˜¯ç›´æ¥é€€å‡º

---

## 6. ç½‘ç»œç¼–ç¨‹ä¸å¼‚æ­¥I/O

### 6.1 å¼‚æ­¥I/Oæ¨¡å‹

**é¡¹ç›®èƒŒæ™¯**ï¼šéœ€è¦ä»è¿œç¨‹æœåŠ¡å™¨ä¸‹è½½å®éªŒæ•°æ®ã€‚

**æ ¸å¿ƒä»£ç **ï¼š
```python
# python/qtomography/infrastructure/network/async_downloader.py
import asyncio
import aiohttp
import aiofiles
from pathlib import Path
from typing import List, Optional

class AsyncDownloader:
    """å¼‚æ­¥ä¸‹è½½å™¨"""
    
    def __init__(self, max_concurrent: int = 5):
        self.max_concurrent = max_concurrent
        self.semaphore = asyncio.Semaphore(max_concurrent)
    
    async def download_file(self, url: str, local_path: Path) -> bool:
        """ä¸‹è½½å•ä¸ªæ–‡ä»¶"""
        async with self.semaphore:  # é™åˆ¶å¹¶å‘æ•°
            try:
                async with aiohttp.ClientSession() as session:
                    async with session.get(url) as response:
                        if response.status == 200:
                            async with aiofiles.open(local_path, 'wb') as f:
                                async for chunk in response.content.iter_chunked(8192):
                                    await f.write(chunk)
                            return True
                        else:
                            logging.error(f"Failed to download {url}: {response.status}")
                            return False
            except Exception as e:
                logging.error(f"Download error for {url}: {e}")
                return False
    
    async def download_batch(self, urls: List[str], 
                           output_dir: Path) -> List[bool]:
        """æ‰¹é‡ä¸‹è½½æ–‡ä»¶"""
        tasks = []
        for url in urls:
            filename = Path(url).name
            local_path = output_dir / filename
            task = self.download_file(url, local_path)
            tasks.append(task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        return [not isinstance(r, Exception) for r in results]
    
    async def download_with_progress(self, url: str, local_path: Path,
                                  progress_callback: Optional[callable] = None):
        """å¸¦è¿›åº¦å›è°ƒçš„ä¸‹è½½"""
        async with aiohttp.ClientSession() as session:
            async with session.get(url) as response:
                total_size = int(response.headers.get('Content-Length', 0))
                downloaded = 0
                
                async with aiofiles.open(local_path, 'wb') as f:
                    async for chunk in response.content.iter_chunked(8192):
                        await f.write(chunk)
                        downloaded += len(chunk)
                        
                        if progress_callback and total_size > 0:
                            progress = downloaded / total_size
                            progress_callback(progress)
```

**é¢è¯•è¦ç‚¹**ï¼š

1. **å¼‚æ­¥I/Oçš„ä¼˜åŠ¿**ï¼š
   - éé˜»å¡ï¼šä¸ç­‰å¾…I/Oå®Œæˆ
   - é«˜å¹¶å‘ï¼šå•çº¿ç¨‹å¤„ç†å¤§é‡è¿æ¥
   - èµ„æºæ•ˆç‡ï¼šå‡å°‘çº¿ç¨‹/è¿›ç¨‹å¼€é”€

2. **å¼‚æ­¥ç¼–ç¨‹æ¨¡å¼**ï¼š
   - åç¨‹ï¼ˆcoroutineï¼‰ï¼šä½¿ç”¨`async/await`
   - äº‹ä»¶å¾ªç¯ï¼š`asyncio.run()`
   - å¹¶å‘æ§åˆ¶ï¼š`asyncio.Semaphore`

### 6.2 ç½‘ç»œè¶…æ—¶ä¸é‡è¯•

**é¡¹ç›®èƒŒæ™¯**ï¼šç½‘ç»œä¸ç¨³å®šæ—¶éœ€è¦é‡è¯•æœºåˆ¶ã€‚

**æ ¸å¿ƒä»£ç **ï¼š
```python
# python/qtomography/infrastructure/network/retry_client.py
import asyncio
import aiohttp
from typing import Optional, Callable
import random

class RetryClient:
    """å¸¦é‡è¯•æœºåˆ¶çš„HTTPå®¢æˆ·ç«¯"""
    
    def __init__(self, max_retries: int = 3, 
                 base_delay: float = 1.0,
                 max_delay: float = 60.0):
        self.max_retries = max_retries
        self.base_delay = base_delay
        self.max_delay = max_delay
    
    async def get_with_retry(self, url: str, 
                           timeout: Optional[float] = 30.0,
                           retry_callback: Optional[Callable] = None) -> Optional[str]:
        """å¸¦é‡è¯•çš„GETè¯·æ±‚"""
        
        last_exception = None
        
        for attempt in range(self.max_retries + 1):
            try:
                timeout_config = aiohttp.ClientTimeout(total=timeout)
                async with aiohttp.ClientSession(timeout=timeout_config) as session:
                    async with session.get(url) as response:
                        if response.status == 200:
                            return await response.text()
                        else:
                            raise aiohttp.ClientResponseError(
                                request_info=response.request_info,
                                history=response.history,
                                status=response.status
                            )
            
            except Exception as e:
                last_exception = e
                
                if attempt < self.max_retries:
                    # è®¡ç®—é€€é¿å»¶è¿Ÿ
                    delay = min(
                        self.base_delay * (2 ** attempt) + random.uniform(0, 1),
                        self.max_delay
                    )
                    
                    logging.warning(f"Request failed (attempt {attempt + 1}), "
                                  f"retrying in {delay:.2f}s: {e}")
                    
                    if retry_callback:
                        retry_callback(attempt + 1, delay, e)
                    
                    await asyncio.sleep(delay)
                else:
                    logging.error(f"All retry attempts failed: {e}")
        
        raise last_exception
```

**é¢è¯•è¦ç‚¹**ï¼š

1. **é‡è¯•ç­–ç•¥**ï¼š
   - æŒ‡æ•°é€€é¿ï¼šå»¶è¿Ÿæ—¶é—´é€æ¸å¢åŠ 
   - éšæœºæŠ–åŠ¨ï¼šé¿å…é›·ç¾¤æ•ˆåº”
   - æœ€å¤§é‡è¯•æ¬¡æ•°ï¼šé˜²æ­¢æ— é™é‡è¯•

2. **è¶…æ—¶å¤„ç†**ï¼š
   - è¿æ¥è¶…æ—¶ï¼šå»ºç«‹è¿æ¥çš„æ—¶é—´é™åˆ¶
   - è¯»å–è¶…æ—¶ï¼šç­‰å¾…å“åº”çš„æ—¶é—´é™åˆ¶
   - æ€»è¶…æ—¶ï¼šæ•´ä¸ªè¯·æ±‚çš„æ—¶é—´é™åˆ¶

---

## 7. æ€§èƒ½ä¼˜åŒ–ä¸è°ƒè¯•

### 7.1 æ€§èƒ½åˆ†æå·¥å…·

**é¡¹ç›®èƒŒæ™¯**ï¼šéœ€è¦åˆ†æé‡æ„ç®—æ³•çš„æ€§èƒ½ç“¶é¢ˆã€‚

**æ ¸å¿ƒä»£ç **ï¼š
```python
# python/qtomography/infrastructure/profiling/performance_profiler.py
import cProfile
import pstats
import time
import tracemalloc
from contextlib import contextmanager
from typing import Dict, Any
import functools

class PerformanceProfiler:
    """æ€§èƒ½åˆ†æå™¨"""
    
    def __init__(self):
        self.profiler = cProfile.Profile()
        self.memory_traces = {}
    
    @contextmanager
    def profile_function(self, func_name: str):
        """åˆ†æå‡½æ•°æ€§èƒ½"""
        # å¼€å§‹å†…å­˜è·Ÿè¸ª
        tracemalloc.start()
        
        # å¼€å§‹æ€§èƒ½åˆ†æ
        self.profiler.enable()
        start_time = time.time()
        
        try:
            yield
        finally:
            # ç»“æŸåˆ†æ
            end_time = time.time()
            self.profiler.disable()
            
            # è·å–å†…å­˜ä½¿ç”¨æƒ…å†µ
            current, peak = tracemalloc.get_traced_memory()
            tracemalloc.stop()
            
            # è®°å½•ç»“æœ
            self.memory_traces[func_name] = {
                'execution_time': end_time - start_time,
                'memory_current': current,
                'memory_peak': peak
            }
    
    def get_profile_stats(self) -> pstats.Stats:
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        return pstats.Stats(self.profiler)
    
    def print_top_functions(self, count: int = 10):
        """æ‰“å°æœ€è€—æ—¶çš„å‡½æ•°"""
        stats = self.get_profile_stats()
        stats.sort_stats('cumulative')
        stats.print_stats(count)
    
    def save_profile_report(self, filename: str):
        """ä¿å­˜æ€§èƒ½æŠ¥å‘Š"""
        stats = self.get_profile_stats()
        stats.dump_stats(filename)

# è£…é¥°å™¨ç‰ˆæœ¬
def profile_method(func):
    """æ€§èƒ½åˆ†æè£…é¥°å™¨"""
    @functools.wraps(func)
    def wrapper(self, *args, **kwargs):
        profiler = getattr(self, '_profiler', None)
        if profiler is None:
            self._profiler = PerformanceProfiler()
            profiler = self._profiler
        
        with profiler.profile_function(func.__name__):
            return func(self, *args, **kwargs)
    
    return wrapper

# ä½¿ç”¨ç¤ºä¾‹
class MLEReconstructor:
    @profile_method
    def reconstruct(self, probabilities: np.ndarray) -> np.ndarray:
        """é‡æ„æ–¹æ³•ï¼Œè‡ªåŠ¨æ€§èƒ½åˆ†æ"""
        # æ‰§è¡Œé‡æ„...
        pass
```

**é¢è¯•è¦ç‚¹**ï¼š

1. **æ€§èƒ½åˆ†æå·¥å…·**ï¼š
   - `cProfile`ï¼šPythonå†…ç½®æ€§èƒ½åˆ†æå™¨
   - `tracemalloc`ï¼šå†…å­˜ä½¿ç”¨è·Ÿè¸ª
   - `line_profiler`ï¼šé€è¡Œæ€§èƒ½åˆ†æ

2. **æ€§èƒ½ä¼˜åŒ–ç­–ç•¥**ï¼š
   - è¯†åˆ«çƒ­ç‚¹å‡½æ•°
   - ä¼˜åŒ–ç®—æ³•å¤æ‚åº¦
   - å‡å°‘å†…å­˜åˆ†é…
   - ä½¿ç”¨ç¼“å­˜

### 7.2 å†…å­˜æ³„æ¼æ£€æµ‹

**é¡¹ç›®èƒŒæ™¯**ï¼šé•¿æ—¶é—´è¿è¡Œå¯èƒ½å‘ç”Ÿå†…å­˜æ³„æ¼ã€‚

**æ ¸å¿ƒä»£ç **ï¼š
```python
# python/qtomography/infrastructure/debugging/memory_monitor.py
import tracemalloc
import gc
import psutil
import os
from typing import Dict, List
import weakref

class MemoryMonitor:
    """å†…å­˜ç›‘æ§å™¨"""
    
    def __init__(self):
        self.snapshots = []
        self.object_refs = weakref.WeakSet()
    
    def start_monitoring(self):
        """å¼€å§‹å†…å­˜ç›‘æ§"""
        tracemalloc.start()
        self._take_snapshot("start")
    
    def _take_snapshot(self, label: str):
        """æ‹æ‘„å†…å­˜å¿«ç…§"""
        snapshot = tracemalloc.take_snapshot()
        self.snapshots.append((label, snapshot))
        
        # è®°å½•å½“å‰å†…å­˜ä½¿ç”¨
        process = psutil.Process(os.getpid())
        memory_info = process.memory_info()
        
        logging.info(f"Memory snapshot '{label}': "
                    f"RSS={memory_info.rss / 1024 / 1024:.1f}MB, "
                    f"VMS={memory_info.vms / 1024 / 1024:.1f}MB")
    
    def compare_snapshots(self, label1: str, label2: str):
        """æ¯”è¾ƒä¸¤ä¸ªå¿«ç…§"""
        snap1 = next(s for l, s in self.snapshots if l == label1)
        snap2 = next(s for l, s in self.snapshots if l == label2)
        
        top_stats = snap2.compare_to(snap1, 'lineno')
        
        print(f"Memory comparison: {label1} -> {label2}")
        for stat in top_stats[:10]:
            print(stat)
    
    def detect_leaks(self):
        """æ£€æµ‹å†…å­˜æ³„æ¼"""
        if len(self.snapshots) < 2:
            return
        
        current_snapshot = self.snapshots[-1][1]
        previous_snapshot = self.snapshots[-2][1]
        
        # æ¯”è¾ƒå¿«ç…§
        top_stats = current_snapshot.compare_to(previous_snapshot, 'lineno')
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ˜¾è‘—çš„å†…å­˜å¢é•¿
        total_increase = sum(stat.size_diff for stat in top_stats if stat.size_diff > 0)
        
        if total_increase > 10 * 1024 * 1024:  # 10MB
            logging.warning(f"Potential memory leak detected: "
                          f"{total_increase / 1024 / 1024:.1f}MB increase")
            
            # æ‰“å°æœ€è€—å†…å­˜çš„ä»£ç è¡Œ
            for stat in top_stats[:5]:
                if stat.size_diff > 0:
                    print(f"  {stat}")
    
    def force_gc(self):
        """å¼ºåˆ¶åƒåœ¾å›æ”¶"""
        collected = gc.collect()
        logging.info(f"Garbage collection freed {collected} objects")
    
    def get_memory_usage(self) -> Dict[str, float]:
        """è·å–å½“å‰å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        process = psutil.Process(os.getpid())
        memory_info = process.memory_info()
        
        return {
            'rss_mb': memory_info.rss / 1024 / 1024,
            'vms_mb': memory_info.vms / 1024 / 1024,
            'percent': process.memory_percent()
        }

# ä½¿ç”¨ç¤ºä¾‹
def process_large_dataset():
    monitor = MemoryMonitor()
    monitor.start_monitoring()
    
    try:
        # å¤„ç†æ•°æ®
        data = load_large_dataset()
        monitor._take_snapshot("after_load")
        
        results = process_data(data)
        monitor._take_snapshot("after_process")
        
        # æ£€æŸ¥å†…å­˜æ³„æ¼
        monitor.detect_leaks()
        
    finally:
        monitor.force_gc()
```

**é¢è¯•è¦ç‚¹**ï¼š

1. **å†…å­˜æ³„æ¼æ£€æµ‹æ–¹æ³•**ï¼š
   - ä½¿ç”¨`tracemalloc`è·Ÿè¸ªå†…å­˜åˆ†é…
   - æ¯”è¾ƒä¸åŒæ—¶é—´ç‚¹çš„å†…å­˜å¿«ç…§
   - ä½¿ç”¨`weakref`é¿å…å¾ªç¯å¼•ç”¨

2. **å†…å­˜ä¼˜åŒ–æŠ€å·§**ï¼š
   - åŠæ—¶é‡Šæ”¾ä¸éœ€è¦çš„å¯¹è±¡
   - ä½¿ç”¨ç”Ÿæˆå™¨å‡å°‘å†…å­˜å ç”¨
   - é¿å…å¾ªç¯å¼•ç”¨
   - å®šæœŸè¿›è¡Œåƒåœ¾å›æ”¶

---

## 8. é¢è¯•å®æˆ˜æ¼”ç»ƒ

### 8.1 å¸¸è§é¢è¯•é—®é¢˜

**Q1: å¦‚ä½•è®¾è®¡ä¸€ä¸ªé«˜å¹¶å‘çš„æ–‡ä»¶å¤„ç†ç³»ç»Ÿï¼Ÿ**

**å›ç­”è¦ç‚¹**ï¼š
1. **æ¶æ„è®¾è®¡**ï¼š
   - ä½¿ç”¨ç”Ÿäº§è€…-æ¶ˆè´¹è€…æ¨¡å¼
   - å¤šè¿›ç¨‹å¤„ç†CPUå¯†é›†å‹ä»»åŠ¡
   - å¼‚æ­¥I/Oå¤„ç†æ–‡ä»¶è¯»å†™

2. **å…·ä½“å®ç°**ï¼š
```python
class ConcurrentFileProcessor:
    def __init__(self, max_workers: int = None):
        self.max_workers = max_workers or os.cpu_count()
        self.file_queue = queue.Queue()
        self.result_queue = queue.Queue()
    
    def process_files(self, file_paths: List[Path]):
        # ç”Ÿäº§è€…ï¼šæ‰«ææ–‡ä»¶
        scanner_thread = threading.Thread(
            target=self._scan_files, args=(file_paths,)
        )
        
        # æ¶ˆè´¹è€…ï¼šå¤„ç†æ–‡ä»¶
        with ProcessPoolExecutor(max_workers=self.max_workers) as executor:
            futures = []
            while True:
                try:
                    file_path = self.file_queue.get(timeout=1.0)
                    future = executor.submit(self._process_file, file_path)
                    futures.append(future)
                except queue.Empty:
                    break
        
        # æ”¶é›†ç»“æœ
        results = [future.result() for future in futures]
        return results
```

**Q2: å¦‚ä½•é¿å…æ­»é”ï¼Ÿ**

**å›ç­”è¦ç‚¹**ï¼š
1. **æ­»é”äº§ç”Ÿçš„æ¡ä»¶**ï¼š
   - äº’æ–¥æ¡ä»¶
   - è¯·æ±‚å’Œä¿æŒæ¡ä»¶
   - ä¸å‰¥å¤ºæ¡ä»¶
   - ç¯è·¯ç­‰å¾…æ¡ä»¶

2. **é¢„é˜²ç­–ç•¥**ï¼š
```python
class DeadlockPrevention:
    def __init__(self):
        self.lock_order = {}  # é”çš„è·å–é¡ºåº
        self.lock_timeout = 5.0  # é”è¶…æ—¶æ—¶é—´
    
    def acquire_locks_ordered(self, locks: List[threading.Lock]):
        """æŒ‰å›ºå®šé¡ºåºè·å–é”"""
        acquired_locks = []
        try:
            for lock in sorted(locks, key=id):  # æŒ‰IDæ’åº
                if not lock.acquire(timeout=self.lock_timeout):
                    raise TimeoutError("Failed to acquire lock")
                acquired_locks.append(lock)
            return acquired_locks
        except Exception:
            # é‡Šæ”¾å·²è·å–çš„é”
            for lock in reversed(acquired_locks):
                lock.release()
            raise
```

**Q3: å¦‚ä½•ä¼˜åŒ–å†…å­˜ä½¿ç”¨ï¼Ÿ**

**å›ç­”è¦ç‚¹**ï¼š
1. **å†…å­˜ä¼˜åŒ–ç­–ç•¥**ï¼š
   - ä½¿ç”¨å¯¹è±¡æ± 
   - åŠæ—¶é‡Šæ”¾ä¸éœ€è¦çš„å¯¹è±¡
   - ä½¿ç”¨ç”Ÿæˆå™¨
   - é¿å…å¾ªç¯å¼•ç”¨

2. **å…·ä½“å®ç°**ï¼š
```python
class ObjectPool:
    """å¯¹è±¡æ± ï¼Œå‡å°‘å†…å­˜åˆ†é…"""
    
    def __init__(self, factory_func, max_size: int = 100):
        self.factory_func = factory_func
        self.pool = queue.Queue(maxsize=max_size)
        self.max_size = max_size
    
    def get_object(self):
        """è·å–å¯¹è±¡"""
        try:
            return self.pool.get_nowait()
        except queue.Empty:
            return self.factory_func()
    
    def return_object(self, obj):
        """å½’è¿˜å¯¹è±¡"""
        try:
            self.pool.put_nowait(obj)
        except queue.Full:
            pass  # æ± å·²æ»¡ï¼Œä¸¢å¼ƒå¯¹è±¡

# ä½¿ç”¨ç¤ºä¾‹
matrix_pool = ObjectPool(lambda: np.zeros((16, 16), dtype=complex))

def process_matrix():
    matrix = matrix_pool.get_object()
    try:
        # ä½¿ç”¨çŸ©é˜µ...
        return result
    finally:
        matrix_pool.return_object(matrix)
```

### 8.2 ç³»ç»Ÿè®¾è®¡é¢˜

**é¢˜ç›®ï¼šè®¾è®¡ä¸€ä¸ªåˆ†å¸ƒå¼ä»»åŠ¡è°ƒåº¦ç³»ç»Ÿ**

**è®¾è®¡è¦ç‚¹**ï¼š

1. **ç³»ç»Ÿæ¶æ„**ï¼š
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Master    â”‚    â”‚   Worker1   â”‚    â”‚   Worker2   â”‚
â”‚  (è°ƒåº¦å™¨)    â”‚    â”‚  (æ‰§è¡Œå™¨)   â”‚    â”‚  (æ‰§è¡Œå™¨)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   â”‚                   â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚   Message   â”‚
                 â”‚   Queue     â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

2. **æ ¸å¿ƒç»„ä»¶**ï¼š
```python
class TaskScheduler:
    """ä»»åŠ¡è°ƒåº¦å™¨"""
    
    def __init__(self, redis_client):
        self.redis = redis_client
        self.task_queue = "task_queue"
        self.result_queue = "result_queue"
    
    def submit_task(self, task_id: str, task_data: dict):
        """æäº¤ä»»åŠ¡"""
        task = {
            'id': task_id,
            'data': task_data,
            'status': 'pending',
            'created_at': time.time()
        }
        self.redis.lpush(self.task_queue, json.dumps(task))
    
    def get_result(self, task_id: str, timeout: float = 30.0):
        """è·å–ç»“æœ"""
        start_time = time.time()
        while time.time() - start_time < timeout:
            result = self.redis.hget("results", task_id)
            if result:
                return json.loads(result)
            time.sleep(0.1)
        raise TimeoutError("Result not available")

class TaskWorker:
    """ä»»åŠ¡æ‰§è¡Œå™¨"""
    
    def __init__(self, worker_id: str, redis_client):
        self.worker_id = worker_id
        self.redis = redis_client
        self.task_queue = "task_queue"
        self.result_queue = "result_queue"
    
    def start_working(self):
        """å¼€å§‹å·¥ä½œ"""
        while True:
            try:
                # è·å–ä»»åŠ¡
                task_data = self.redis.brpop(self.task_queue, timeout=10)
                if not task_data:
                    continue
                
                task = json.loads(task_data[1])
                
                # æ‰§è¡Œä»»åŠ¡
                result = self.execute_task(task)
                
                # ä¿å­˜ç»“æœ
                self.redis.hset("results", task['id'], json.dumps(result))
                
            except Exception as e:
                logging.error(f"Worker {self.worker_id} error: {e}")
```

### 8.3 æ•…éšœæ’é™¤åœºæ™¯

**åœºæ™¯1ï¼šç¨‹åºçªç„¶å˜æ…¢**

**æ’æŸ¥æ­¥éª¤**ï¼š
1. **æ£€æŸ¥ç³»ç»Ÿèµ„æº**ï¼š
```python
import psutil

def check_system_resources():
    """æ£€æŸ¥ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ"""
    cpu_percent = psutil.cpu_percent(interval=1)
    memory = psutil.virtual_memory()
    disk = psutil.disk_usage('/')
    
    print(f"CPUä½¿ç”¨ç‡: {cpu_percent}%")
    print(f"å†…å­˜ä½¿ç”¨ç‡: {memory.percent}%")
    print(f"ç£ç›˜ä½¿ç”¨ç‡: {disk.percent}%")
    
    if cpu_percent > 80:
        print("è­¦å‘Šï¼šCPUä½¿ç”¨ç‡è¿‡é«˜")
    if memory.percent > 90:
        print("è­¦å‘Šï¼šå†…å­˜ä½¿ç”¨ç‡è¿‡é«˜")
```

2. **åˆ†ææ€§èƒ½ç“¶é¢ˆ**ï¼š
```python
import cProfile
import pstats

def profile_slow_function():
    """åˆ†ææ…¢å‡½æ•°"""
    profiler = cProfile.Profile()
    profiler.enable()
    
    # æ‰§è¡Œæ…¢å‡½æ•°
    slow_function()
    
    profiler.disable()
    stats = pstats.Stats(profiler)
    stats.sort_stats('cumulative')
    stats.print_stats(10)
```

**åœºæ™¯2ï¼šå†…å­˜æ³„æ¼**

**æ’æŸ¥æ­¥éª¤**ï¼š
1. **ç›‘æ§å†…å­˜ä½¿ç”¨**ï¼š
```python
import tracemalloc

def monitor_memory():
    """ç›‘æ§å†…å­˜ä½¿ç”¨"""
    tracemalloc.start()
    
    # æ‰§è¡Œæ“ä½œ
    process_data()
    
    # è·å–å†…å­˜å¿«ç…§
    snapshot = tracemalloc.take_snapshot()
    top_stats = snapshot.statistics('lineno')
    
    print("å†…å­˜ä½¿ç”¨æœ€å¤šçš„ä»£ç è¡Œï¼š")
    for stat in top_stats[:10]:
        print(stat)
```

2. **æ£€æŸ¥å¾ªç¯å¼•ç”¨**ï¼š
```python
import gc

def check_circular_references():
    """æ£€æŸ¥å¾ªç¯å¼•ç”¨"""
    # è·å–æ‰€æœ‰å¯¹è±¡
    objects = gc.get_objects()
    
    # æ£€æŸ¥å¾ªç¯å¼•ç”¨
    cycles = gc.get_referrers(*objects)
    
    if cycles:
        print(f"å‘ç° {len(cycles)} ä¸ªå¾ªç¯å¼•ç”¨")
        for cycle in cycles:
            print(cycle)
```

---

## æ€»ç»“

è¿™ä»½è¯¦ç»†çš„æ“ä½œç³»ç»Ÿé¢è¯•æ–‡æ¡£åŸºäºæ‚¨çš„é‡å­å±‚æé¡¹ç›®å®é™…ä»£ç ï¼Œæ¶µç›–äº†ï¼š

1. **ç†è®ºåŸºç¡€**ï¼šæ¯ä¸ªæ¦‚å¿µéƒ½æœ‰æ¸…æ™°çš„åŸç†è§£é‡Š
2. **å®æˆ˜ä»£ç **ï¼šæ¥è‡ªé¡¹ç›®çš„çœŸå®ä»£ç ç¤ºä¾‹
3. **é¢è¯•æŠ€å·§**ï¼šå¸¸è§é—®é¢˜çš„å›ç­”æ¨¡æ¿
4. **ç³»ç»Ÿè®¾è®¡**ï¼šåˆ†å¸ƒå¼ç³»ç»Ÿçš„è®¾è®¡æ€è·¯
5. **æ•…éšœæ’é™¤**ï¼šå®é™…é—®é¢˜çš„æ’æŸ¥æ–¹æ³•

é€šè¿‡å­¦ä¹ è¿™ä»½æ–‡æ¡£ï¼Œæ‚¨å°†èƒ½å¤Ÿï¼š
- æ·±å…¥ç†è§£æ“ä½œç³»ç»Ÿæ ¸å¿ƒæ¦‚å¿µ
- æŒæ¡ç³»ç»Ÿç¼–ç¨‹çš„å®é™…æŠ€èƒ½
- å…·å¤‡é¢è¯•ä¸­çš„é—®é¢˜è§£å†³èƒ½åŠ›
- ç†è§£å¤§å‹ç³»ç»Ÿçš„è®¾è®¡æ€è·¯

å»ºè®®æ‚¨ï¼š
1. ä»”ç»†é˜…è¯»æ¯ä¸ªä»£ç ç¤ºä¾‹
2. åŠ¨æ‰‹è¿è¡Œå’Œä¿®æ”¹ä»£ç 
3. æ¨¡æ‹Ÿé¢è¯•åœºæ™¯è¿›è¡Œç»ƒä¹ 
4. ç»“åˆå®é™…é¡¹ç›®åŠ æ·±ç†è§£

è¿™æ ·æ‚¨å°±èƒ½åœ¨é¢è¯•ä¸­å±•ç°å‡ºæ‰å®çš„æ“ä½œç³»ç»ŸåŸºç¡€å’Œä¸°å¯Œçš„å®æˆ˜ç»éªŒï¼
